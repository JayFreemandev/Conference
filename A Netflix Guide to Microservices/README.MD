# 넷플릭스의 마이크로서비스

15년전 장모님이 응급실에 실려갔는데 이미 몸이 마비가 된 상태였다. Guliain? 무슨 특수한 면역 질환이였고  
외부 요인에 의해 신경 세포가 스스로 망가지는 병이였다. 여러 요법들을 시도했고 운이 좋게도 성공했다.  
  
다시 그 병에 걸리지 않으려고 건강하게 먹고 운동도 더 하고 그렇게 살고있는데 세상에는 별 일이 다 생기고        
나쁜 박테리아 등등 많은 일이 생긴다. 이런 세상에서 사람이 숨쉬는 행동만해도 세상과 상호작용도 하고 정말 기적같고 용감한 행동이다.                   
  
마이크로서비스 설명하러와서 왜 이런소리하냐?       
이런 세상에서 용감하게 숨쉬는 행동들이 마이크로서비스 아키텍처에서 트래픽을 가져오는것이다.    
  
  
![image](https://user-images.githubusercontent.com/72185011/173217775-4b253e63-2291-4d80-85dc-b4bf518aa69b.png)  

트래픽이 폭증할수도있고 디도스 공격을 받을수도있고 시스템이 전체적으로 다운되서 고객들이 서비스 이용을 못할수도있다.            
오늘의 주제인 마이크로 서비스 아키텍처는 좋은점도 있고 힘든점도 있다.                 
넷플릭스에서 7년동안 여러 종류의 실패에서 짱구를 굴리며 발견한 문제와 솔루션에 대해 이야기 할거다.    

마이크로 서비스에 대한 추상적인 설명에 앞서 마이크로 서비스가 아닌거에 대해 먼저 이야기하고싶다.  

![image](https://user-images.githubusercontent.com/72185011/173218034-d41af445-183b-4568-b0b9-f1ca7977197a.png) 

2000년대 초반에는 단순한 인프라 구조를 가지고있었다.  
자바 기반의 모놀리틱 코드 방식의 아키텍쳐는 하나의 코드 베이스를 주마다 배포하는데 문제는 뭐 변경하다가 에러날경우에    
날밤을 새워가며 문제점 찾아야했다. 코드 다시 빼보고 다시 돌려보고 하나에 어플리케이션에 코드를 다 집어넣어놨기 때문이다.   

모놀리식으로 사용된 데이터베이스 경우에는 더 심각했다. 오라클죽으면 서버 전체 다운된다.       
휴가마다 더 큰 하드웨어 찾으러다녔다 수직 확장시켜서 스케일업을 해야되기 때문이다.                   
엔지니어링 관점에서보면 매우 고통스럽다. 너무 타이트하게 서로 상호작용하기때문에 문제가 생길시 빠르게 대처할수없었다.        

위와 같은 구조의 예시들이 90년대하고 2000년대 초반에는 일반적인 패턴이였지만   
위와 같은 이유로 오늘날 서비스 구축을 저렇게 하지 않는 이유이다.  

그럼 마이크로 서비스는 뭔가?  

![image](https://user-images.githubusercontent.com/72185011/173218542-4987a64c-7ff9-4f97-919a-67e6aea518f1.png)

각각 자체 프로세스에서 실행하고 가벼운 방법으로 접근하는 소규모 서비스들의 모음으로 단일 애플리케이션을 개발하는 접근 방식이다.   
마틴 파울러가 설명한 마이크로서비스의 정의지만 다소 추상적이다.  
기술적으로는 틀린말이 하나 없는데 2% 부족하다.   
   
마이크로 서비스를 구축한다는게 무엇을 의미하는지에 대해 설명이 부족한거같아서 내가 2000년대 겪었던 경험을 좀 덧대보자면 관심사분리다.   
워크로드를 분산시키고 수평적으로 확장할수있는 확장성(Scalability), 가상화와 자동화다.

![image](https://user-images.githubusercontent.com/72185011/173218732-5d6e8b2a-1be1-40aa-bc3e-330dd7aa14b3.png)
            
아까 숨쉬는거 마저 이야기하자면 이 모든 장기들은 각자 할일을 하고 할일들이 모여 전체적인 조화를이룬다.    
                     
![image](https://user-images.githubusercontent.com/72185011/173218878-0e53998e-3fd3-470a-94b5-35809b84c77a.png)
                
영상에서보면 선들하고 저 딱콩들에서 무언가가 실시간으로 움직임  
ELB뒤에 동적 라우팅을 담당하는 Zuul이라는 프록시 레이어가 있다.  
앞에는 NCCP라고하는 레거시 티어가 있는데 이전 장비를 호환시켜주고 기본적인 동영상 재생을 시켜준다.                         
                            
![image](https://user-images.githubusercontent.com/72185011/173218919-cf31254c-2342-4182-a068-f3696f82f41f.png)

넷플릭스 API는 API 게이트웨이를 통해 호출되는데 이게 오늘날 모던 아키텍쳐의 핵심이다.  
외부 고객들의 모든 요청을 받기 위해 다른 서비스들을 호출한다.  
해당 계층을 엣지 서비스라고 한다.                                        
                            
![image](https://user-images.githubusercontent.com/72185011/173219038-17af2b31-2c4b-435d-9360-fdd18645aa35.png)

오른족으로 갈수록 미드티어와 플랫폼 단계이다.    
구독 서비스, 추천 서비스, 라우팅 서비스, 암호화 서비스, 데이터 보존 서비스등   
어플리케이션의 오브젝트들처럼 전체 생태계의 일부처럼 동작한다.                      
                                   
![image](https://user-images.githubusercontent.com/72185011/173219101-5677936f-3a08-41aa-bc2b-5b325b2c168d.png)

마이크로 서비스는 추상적이다. 
우리는 단순하게 이해하려는 경향이 있는데 "수평적으로 잘 확장되니 별 문제 없이 접근하겠지"  

그렇게 간단하지가 않다.  
언젠가 데이터를 영구 저장할 DB가 필요할거다.  
어떤 시점에는 캐시가 필요하게 될거다.    

서비스와 DB가 빠릿빠릿 대응못할수도 있어서 클라이언트에서 사용할 캐시들도 필요하다.   
캐시에 먼저 접근해서 실패하면 서비스로가고 DB 응답 다시 반환하고 다시 부를때 반환값들을 
다시 캐시에 넣어서 다음번에는 눈깜짝할사이에 콜할수있게될거다.  

클라이언트 관점에서 살펴보면 이 전체적인 기술들과 설정의 조합이 마이크로 서비스고     
‘무상태(Stateless)같이 이론적으로 간단한게 아니라 복잡하다.   
실제로는 이 구조를 감싸고있는 복잡한 설계를 이해해야한다.    

그래서 이제 넷플릭스가 봉착했던 문제들과 해결한 방법 그리고 철학에 대해서 이야기해보려고한다.  
4가지의 주제로 설명할수있다.  

1. Dependency
2. Scale
3. Varience within your architecture
4. Change

# Dependency
의존성의 유즈 케이스들을 다음과 같은 4가지로 설명할 수 있다.   
  
- Intra-Service requests
- Client librariesData
- Persistence
- Infrastructure

## Infra-service-requests

큰 요청들을 수행하기위해서 마이크 서비스A에서 마이크로 서비스 B를 호출하는거라 보면 된다.  
프로세스와 서버를 벗어나 다른 서버의 프로세스까지 도달해야되는데    

네트워크 지연문제, 하드웨어 오류, 트래픽이나 라우팅 문제나 호출한 서비스가 정상이 아닐수있다.    
많이 발생하는 대참사 시나리오중 만약 A에서 B호출했는데 의존관계에 엮여있는 서비스들을 모두 터트려 버린다면?    

![image](https://user-images.githubusercontent.com/72185011/173221231-49340d69-3ac7-413b-981d-15946adfe6c0.png)

하나의 실패가 연쇄적으로 일어나 전체적으로 문제를 일으킨다.  
이 문제를 해결하고자 넷플릭스에서는 터진 서비스를 제자리에서 수정하기위해 Hystrix를 고안해냈고 넷플릭스의 혁신이였다.  

![image](https://user-images.githubusercontent.com/72185011/173221241-fc059656-14b1-4c12-84e9-3370ad15b684.png)

한 서비스를 호출하다 문제가 생길경우 에러터트리는게 아니라   
정적인 리스폰스값을 제공해사용자는 계속 동작하는 것처럼 보이게 한다.   
  
스레드풀을 고립과 서킷회로 개념들을 이용하는것이 큰 장점중 하나인데.  
서비스 호출이 안되는데 계속 호출보내는것보다 호출 중지시키는게 맞는 방법이다.  

장애가 감지되면 지정된 fallback으로 응답하고 서비스가 복구되길 기다린다.   
오늘날 넷플릭스는 Hystrix를 넓은 범위에 적용하여 사용하고있다.  

![image](https://user-images.githubusercontent.com/72185011/173221273-05270486-4c29-4122-b6e8-23aaaca530bd.png)

여기서 의문점은 일단 위에 장점이 있는거는 알겠는데 이게 대규모에도 효과가 적용될지 어떻게 알까?     
예방접종 방식과 비슷하다. 우리가 백신 맞으면 죽은 바이러스를 넣어서 내성을 가진 항체를 만들고   
항체 만들어지면 살아 있는 바이러스 넣어서 실험한다.   

![image](https://user-images.githubusercontent.com/72185011/173221326-4b655580-2f91-4dc2-baab-060a2ec3c376.png)
요청 실패를 유발하는 설정들을 주입해보고 라이브 트래픽 비율을 조정해보면서 실제 라이브 트래픽을 100%까지 점진적으로 올려 확인한다.

![image](https://user-images.githubusercontent.com/72185011/173221339-d27798e9-aad0-4b64-8057-6152f60c8946.png)

위의 그림은 point to point 관점이다.   
100개의 마이크로 서비스가 동작중이라고 가정해보자.   
테스트 범위를 어떻게 해야 100개 전부 통신하는거를 시뮬레이션 없이 테스트 해볼수있을까?   

넷플릭스는 테스트 목적 달성을 위해 치명적인 장애들을 정하고 테스트에 필요한 필수적인 서비스들을 추려낸다. 
예를들어, 사용자가 영화를 보기 위해 클릭하는 시나리오들을 그룹화시키고 이 외에는 전부 블랙 리스트로 처리한다. 
그룹화된 테스트들만 진행한다. 

그러면 의존성이 있는 서비스들이 동작하지 않는 상태로 만들어서 장애가 일어날때 어떻게 동작하는지 테스트한다.   
이렇게 테스트르하면 point to point 연동을 확인하지 않아도 되서 단순하고     
넷플릭스 서비스에 존재하는 치명적인 문제들을 찾아내는데 매우 큰 도움을 주었다.    

## Client libraries

처음 클라우드로 서비스를 이전하며 클라이언트 라이브러리에 대해 말이 많았다.    
야후에서 코드 좀 치는 개발자들이 넷플릭스로 많이 넘어왔다.    
특정 기술에 대한 광신도들이 많았고 클라이언트 라이브러리 사용하지도 않고 특정 기술로만 모든 요청을 처리했다.   

이와 동시에 클라리언트 라이브러리를 만들어야 한다는 주장도 강했다.    
공통 로직과 공통 접근 패턴을 가지고 있을때 20~30개의 서비스에 유사한 코드를 매번 작성해야하나     
그냥 공통 비지니스 모델로 묶고 공통적인 접근 패턴을 사용하는게 맞지않냐   

잘못하면 새로운 형태의 모놀리틱 형태가 될수도있는 문제점을 가지고있었다.   
수백개의 서비스 연결을 처리하는 API 게이트웨이가 있다.    

이 API 게이트웨이는 결국 2000년대 초반의 악몽과도 같은 모놀리틱처럼 거대한 코드베이스가 되어있었다.  

![image](https://user-images.githubusercontent.com/72185011/173221484-a4a1a4bb-d9e8-4a11-8633-4a337ad3d01c.png)

기생충 감염을 생각해보자.. 고질라같이 거대해서 도쿄를 무너뜨리지는 않겠지만 당신의 창자를 창내기에는 충분하다.
무지성 클라이언트 라이브러리 또한 내부에서 오류를 일으키는 논리적 결함이 있을수도있고  
의존성있는 라이브러리끼리 버전이 다를때도 문제를 일으킬수있다.   

실제로 API팀에서 발생했고 너무 많은 팀의 라이브러리들을 사용해서 생긴 문제다.   
아직까지 이건 이렇게 해야한다 라는 정답이 없기에 결론나지않은 문제다.     

![image](https://user-images.githubusercontent.com/72185011/173221900-a9d71d2f-250d-4b1f-972a-1cef1774afef.png)

가장 최근 방법은 라이브러리를 심플한 규모로 만들면 되지 않을까인데 논의중이라 결론이 난 방법은 아니고   
이걸 왜 말했냐면 어떤 상황에 어떤 것을 선택해야하는지에 대한 생각을 공유하기 위함이다.  

## Data Persistence

넷플릭스가 초반에 잘 구성해서 문제가 일어난 전쟁같은 스토리는 없다. 대신에 어떻게 잘 구성했는지 이야기하겠다.  
CAP 이론을 어떻게 옳게 구성할까인데 네트워크가 분리되었을때 가용성과 일관성(consistency and availability)중 하나를 선택해야된다는 거다.  

최근 하드웨어가 발전하고, 검색 서비스, SNS 서비스 같은 대규모 데이터 처리 및 장애 상황에서도 서비스를 유지해야하는   
특성을 반영하여 BASE 라는 속성에 맞는 데이터 관리 시스템이 필요로 하게 되었다.  

결국 확장성과 고가용성을 제공해야하지만, 표준 SQL이나 엔티티 간의 관계를 지원하지 않는 데이터 관리 시스템이 등장하게 되었으며,   
이러한 시스템을  NoSQL이라고 한다. 분산환경의 NoSQL 시스템을 구성할 경우 CAP 이론이라는 것이 있다.   

CAP 이론은 CAP 속성을 정의한것으로 “적절한 응답 시간내에 세 가지 속성을 모두 만족시키는 분산 시스템을 구성할 수 없다”라고 정의한 이론이다.  

![image](https://user-images.githubusercontent.com/72185011/173221924-32bdab26-c9f3-4879-a699-7b1b83e8f6f7.png)

관계형 데이터베이스는 정합성(C)과 가용성(A)에 초점이 맞춰져 있는 반면,   
NoSQL 솔루션들은 가용성(A) – 단절내성(P) 또는 정합성(C)-단절내성(P) 특성을 제공한다.            
CAP 이론에 따라 분산된 환경에서는 세 가지 속성을 동시에 만족시킬 수 없기 때문에             
저장되는 데이터의 속성과 요구사항을 파악해 요구사항에 어떤 속성을 갖는지를 알아야 한다.      

네트워크 A에서 동작하는 서비스가 있을때 동일한 데이터를 여러개에 DB에 저장하려고한다.   
이 DB들은 서로 다른 네트워크에 존재한다.  

![image](https://user-images.githubusercontent.com/72185011/173221936-d5797c98-8673-43ca-8611-b586ab199cb0.png)

여기서 의문점은 만약 한개 이상의 DB에 접근이 안된다면?   
그냥 실패로 처리할건지 에러를 리턴할지 아니면 일단 저장할수있는곳에 저장하고 나중에 고쳐지면 복붙할건지다.   

넷플릭스는 최종 일관성(eventual CONSISTENCY)를 선택했고 데이터를 저장하고 난 직후 데이터를 READ 하지 않는다.   

![image](https://user-images.githubusercontent.com/72185011/173221953-974e3ee3-8deb-424d-9a8c-9a2777f3b299.png)

이런 작업을 카산드라가 끝내주게 하는데. 클라이언트가 하나인 노트에 데이터를 넣어도 데이터들을 모든 노드에 알아서 복제할만큼 유연하다.
local quorum이라는 기능이 있는데. 정합성 레벨(consistency level)을 제공하여 가용성을 높인다.   
무슨 소리냐 지정한 레벨보다 낮으면 노드가 다운되어도 서비스의 다운타임이 발생하지 않는다.  

예를 들어 데이터를 복붙해야하는 DB가 3개고 이중 노드 하나가 죽었으면 저장 요청이 왔을때   
다운된 노드에 복붙을 못하기때문에 요청 결과에 성공을 반환하지않는다.  

하지만 1로 설정하면 동작하는 노드가 설정한 레벨만큼 있으면 바로 성공을 반환한다.   
노드 하나가 죽어도 데이터를 읽고 쓰는데 문제가 없게할수있는 특징이 있다.  

대신에 장애 시 데이터 복구 시간이 오래 걸린다 왜냐 복구 과정상 복구할 데이터들을 모두 알아내고   
각 데이터마다 최신 버전을 읽어서 다시 저장시키는 방식이기 때문이다.  

복구 작업하는 동안 서비스 요청도 받을수있어서 읽기하다가 잘못된 값을 반환할수도있어서 복구 되기전에 요청보내면 틀린 결과를 반환할수도있음.   

## Infrastructure
![image](https://user-images.githubusercontent.com/72185011/173221995-f3418bd8-ced7-4759-8847-13448c58c648.png)                         
2012년 크리스마스 이브에 AWS 장애가 발생했다.                     
ELB의 제어 부분이 다운되었는데 하필 넷플릭스의 모든 리소스가 한곳에 있었다.                                         

![image](https://user-images.githubusercontent.com/72185011/173222004-62bcb03b-53a8-4418-9573-9d5ffdc5522e.png)                               
계란을 한바구니에 담은거처럼 us-east-1에 있었다.   
해당 region이 터지고 난 후 손가락을 쪽쪽 빨아야했다.  
                 
아마존이 aws 서비스를 못하는게 아니다.                  
어떤 AWS던 니가 직접 구성한 인프라건 장애는 반드시 발생한다.                      

![image](https://user-images.githubusercontent.com/72185011/173222026-eafff488-3c95-4f24-b21a-e65af07076bc.png)                                  
계란이 모두 깨진 넷플릭스는 공포의 쓴맛을 기억하며 멀티 AWS region을 구성했다.             
계란을  여러 바구니에 담아서 하나 터져도 서비스에 지장이 가지 않게 말이다.              

# Scale
3가지 케이스가 있다.

- Stateless services
- Stateful services
- Hybrid services

## Stateless service란?

- cache x DB x
- 메모리에 자주 접근하는 메타데이터가 캐시로 되어있음
- 사용자는 하나의 인스턴스에 종속되지 않고 노드 죽어도 새로 생성쉬움

세션 정보를 server에 담지 않아서 세션 state에 무관한 응답을함 이게 무슨말이냐   
클라이언트가 A의 요청을 하는 경우  고정된 서버에서만 관리 할 필요가 없다는 소리다.     

굳이 필요한 정보가 있다면 외부 DB에 저장하지 서버는 저장안함.   

언급하는 이유는 Stateless service는 Scaling에 자유로운 구조이기 때문이다.     

![Untitled 23](https://user-images.githubusercontent.com/72185011/174320676-5738ed33-7496-4191-809d-67f265d2f037.png)

생물학으로 돌아가서 

이 계란후라이같이 생긴게 분열을 하면서 필요에 따라 세포를 만들 수 있거나 세포가 계속 죽어가고 있는 것처럼 보이면서 복제한다.  

Auto Scaling이 그렇다.

![Untitled 22](https://user-images.githubusercontent.com/72185011/174320843-369ec4cf-94af-44db-ac1e-738ae44c97da.png)

최대값 최소값 사이즈를 정하고 새 인스턴스를 확장해야할때 (on demand) 방식으로   
S3에 이미지 가져와서 필요한만큼 세포마냥 쭈욱 쭈욱 늘린다.   

필요할때 늘려서 컴퓨팅 효율성도 좋고 노드가 쉽게 교체된다.    

해당 기술의 장점은 디도스 공격이나 문제가 생겼을때 스케일링을 늘려   
실제로 무슨 일이 일어났는지 파악하는 동안 세포 분열하듯이 장애 사항을 흡수해버린다.  

## 그럼 Stateful service란?

- DB & Caches
- hold large amounts of data

세션에 상태에 따라 서버의 응답이 달라지는 3 way handshake나 데이터 전송시 패킷헤더를 하싱하여    
앞으로 수신해야할 데이터 크기, 시퀸스를 저장하고 다 수신될때까지 세션을 유지하는것도 Stateful service의 예시중 하나이다.  

Stateful 구조에서 노드 하나가 고장나면 새로 갈아 끼우는데 땀이 삐질흘릴거다.   
내가 있을 당시에 야후에 좀 치는 개발자들이 있었다고 했는데 이 사람들이 HA Proxy랑 squid cache 경험이 있는 사람들이였다.    

![Untitled 25](https://user-images.githubusercontent.com/72185011/174321140-0a52d4bc-f42b-43bb-91a7-8c4f8ab37717.png)

그리고 이 사람들 패턴이 있는데 고객이 요청하면 언제나 같은 노드에서 캐시를 가져가게 하는거다.   
그렇기에 하나가 터지면 이 캐시를 이용하는 고객들은 서비스 이용에 문제가 생기게된다.   

더 심각했던거는 히스트릭스가 없었던 이전 상황이고 따로 복구할 벌크 헤딩, 분리,    
쓰레드풀 고립이 안되있어서 한 노드가 죽으면 넷플릭스 전체가 다운되버렸다.  
노드 하나 복구하는데 3시간 넘게 걸렸음.   

그래서 이런 Single point failure pattern이 안좋다는거다.   
다시 생물학으로 돌아가서 중복성이라는거는 기본적이다. 
우리 몸은 두 개의 신장, 두 개의 폐를 가지고 있으므로 하나가 기능을 못하더라도 당장 죽지는 않는다.   우리 몸도 그렇듯 넷플릭스는 EVCache Writes라는 기술을 적용했다.  

노드 하나 죽으면 다른 환경 노드 사용하는거다.  

![Untitled 26](https://user-images.githubusercontent.com/72185011/174321321-e27ccde1-5a2b-4288-aa81-28e8994c6ae9.png)

Memcached로 wrapping한 기술인데 위에 나오는 오징어 캐시랑 유사하게 분할되지만   
저장이 일어 날때마다 복사본이 여러 노드에 기록된다.   
자기 구역에 있는것만 읽어오지만 장애 났을때는 다른 구역 넘나들며 읽어오기 가능함    

Hybrid Microservice

EVCache를 사용하는데 여기 또 너무 의존하니까 EVCache죽으니까 문제 생기더라  
해결책으로는 다음과 같은 방법들이 있는데  

첫째, 실시간으로 Batch를 사용 금지  
두번째, 매번 Request가 서비스 반복 호출하게 하지말고 요청 한 번 받을때 캐시남겨서 나머지 요청은 캐시를 통해 제공  
세번째, Token roll back, 장애가 발생하더라도, Token에 충분한 정보가 있어서 사용자에게 당장 기본 작업을 제공할수있도록 암호화된 토큰으로 백업준비.  
네번째, Chaos(실패 주입)가 일어나게 아키텍쳐 테스트로 해당 장애를 방지.  
 
# Varience within your architecture

**시스템이 다양할수록 관리하기 더 복잡하고 어려워진다.** 

아키텍쳐 내 변형에대해 설명하고 두가지 목차가있다.

- Operational drift
- Polyglot & containers

## Operational drift란

의도하지않은..이라고도 하는데 내가 의도한게 아니라 자연스럽게 그냥 일어남

![Untitled 27](https://user-images.githubusercontent.com/72185011/174321595-af2afcba-3794-452a-8311-7fdf14e5ec3b.png)

서비스를 지속적으로 운영하기 위한 좋은 방법을 찾아냈지만 팀 중 절반만이 실제로 이 방법을 도입했다고 가정해보자

팀원들과 처음 이야기 할때 위에 알림, 타임아웃, 폴백 등 효율적으로 운영하기 좋은 방식들에 대해, 처음에는 열정으로 가득하지만 사람이란게 수동적이고 반복적인거를 싫어한다. 더군다나 내 서비스 제품 작업과 관련이 없기때문에 내 업무 하기 바빠서 나중에는 열정도 식고 피하게 된다.

다시 생물학으로 돌아가자

![Untitled 28](https://user-images.githubusercontent.com/72185011/174321629-8d97d0a3-7cc1-4022-a8e7-5ea5cf89dc2d.png)

이 Autonomic Nervous가 뭐냐? 자율 신경계다 우리가 음식 소화하거나 숨쉬는거에 대해 신경쓰면서 안해도 자연스럽게 되는 행동들이다.  자면서 내가 숨쉬는걸 깜빡해서 죽는 걱정은 하지않는다.

이러한 이상적인 행동을 잠재적으로 할수있는 환경을 조성하는게 중요하다. 넷플릭스는 지속적인 학습과 자동화의 사이클을 구축해냈다. 

![Untitled 29](https://user-images.githubusercontent.com/72185011/174321655-86c1503f-ea4c-4345-a5da-270988d63cd6.png)

장애가 생기고 리뷰와 분석을 통해 배우고 베스트 프랙티스를 자동화시키고 적용했다. 이러한 지식이 코드가되고 직접적으로 마이크로 서비스 구조에 통합시킨다.

![Untitled 30](https://user-images.githubusercontent.com/72185011/174321677-caaedbd9-1d17-42d1-ac06-9d1bf6d3abab.png)


넷플릭스 상용 준비에 필요한 체크리스트다. 이 모든 모듈 하나 하나를 지속적으로 개선해오고있다. 

## Polyglot & Containers

Polyglot은 여러 언어를 쓰는것을 의미함

내가 매니저로 지난 몇년동안 일어난 실제 이야기다. 

![Untitled](A%20Netflix%20Guide%20to%20Microservices%2018f2c9a7107d49af83aabb17fe09fb10/Untitled%2031.png)

Polyglot & Containers를 의도적인 변형이라고도한다. 사람들은 마이크로 서비스에 이 새로운 기술들을 적용하려고 한다. 하는데 3년전에 넷플릭스의 자동화와 통합 기능을 갖춘 기술 스택을 구성하고있었다. 내가 짠대로 따라가면 효율적이고 이상적인 환경을 만들수있는데

일부 힙스터 개발자들은 내가 만들어놓은 도로를 벗어나 직접 도로를 만들고 자바하자니까 파이썬, 루비, 노드로 개발하기 시작했다. 각각 어느 정도의 유의미한 가치를 보여주기는 했는데 도커가 등장하면서 일이 아주 뜨거워졌다.

하나의 도로대신 이제는 인프라팀들의 곡소리를 들을수있는 포장 도로가 여러개생겼다. 이런 모든 케이스들을 유지하는데는 비용이든다 도커 컨테이너비용, 모니터링 등 넷플릭스는 올바른 이러한 문제때문에 지원 범위를 제한하고 재사용 가능한 솔루션을 찾아서 다양성에 대응했다.

# Change

![Untitled](A%20Netflix%20Guide%20to%20Microservices%2018f2c9a7107d49af83aabb17fe09fb10/Untitled%2032.png)

다운되는 시간을 보면 9시 아침에 뻥 터지고 넷플릭스를 분해하기 시작한다.

**어떻게 내가 속도도 빨리하면서 똥을 뿌직 안쌀 자신으로 문제를 해결할까?**

![Untitled 33](https://user-images.githubusercontent.com/72185011/174321803-64395597-0a7a-4f7f-bbb4-389f7d9413f6.png)


새로운 전달 시스템인 스핀에이커가 등장한다. 스핀에이커는 상용에 배포할때 통합 될 수 있도록 모범 사레를 통합하여 설계된 도구다. 예를 들어 새로운 버전의 어플리케이션 배포시 현재 라이브 시스템에서 유입되는 트래픽의 일부를 자동으로 새로 배포중인 어플리케이션에 흘려보내 기존 코드와 새로운 코드를 비교할 수 있게 해준다.

### 쉬어가는 타임

부수적으로 Conway’s Law이야기도 나왔는데 일렉트로닉 딜리버리라는 기능을 넷플릭스에서 제공했다. 현대의 스트리밍느낌임. 서비스와 API를 운영하는 팀이 달라 문제점이 생겼고 소프트웨어는 그걸 만든 팀의 구조를 닮는다. 컴파일러를 만드는 팀이 4개면 4개의 단계를 가지는 컴파일러가 만들어진다. 

두개의 서비스를 합치고나서야 긍정적인 성능 향상을 가져올수있었다. 조직이 먼저가 아니라 해결방안이 먼저다. 일하면서 느끼는거지만 같이 일하고있는 팀내에서도 소통의 부재로 서로 다른 결과물을 만들때가 있었다. 

![Untitled 34](https://user-images.githubusercontent.com/72185011/174321819-00fb5724-90f7-4876-ae94-055eb3de4583.png)

우리 몸과 같이 복잡하고 유기적인 마이크로 서비스 아키텍쳐 

요약

Dependency

- Circuit breakers, fallbacks, chaos
- Simple clients
- Eventual consistency

Scale

- Auto-scaling
- Redundancy, avoid SPoF
- Partioned workloads
- Failure-driven design
- Chaos under load

Variance

- Engineered operations
- Understood cost of variance
- Prioritised support by impact

Change

- Automated delivery
- Integrated practices

Organisation and architecture

- Solutions first, team second
